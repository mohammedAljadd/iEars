{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9e9cd3",
   "metadata": {},
   "source": [
    "# FaceNet\n",
    "- FaceNet is the name of the facial recognition system that was proposed by Google Researchers in 2015 in the paper titled FaceNet: A Unified Embedding for Face Recognition and Clustering\n",
    "\n",
    "- Paper link : https://arxiv.org/abs/1503.03832"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfef89d",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7bf062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FaceNet_src.architecture import * \n",
    "import os \n",
    "import cv2\n",
    "import mtcnn\n",
    "import pickle \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "# Five classes/folders\n",
    "CATEGORIES = [\"aljadd\", \"nossaiba\", \"nouhaila\", \"langze\", \"unknown\"]\n",
    "\n",
    "# Faces path\n",
    "source_face_path = \"dataset/\"\n",
    "destination_face_path = \"FaceNet_src/Faces/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298f1d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Faces folder for new training if needed!\n",
    "folder = 'FaceNet_src/Faces/'\n",
    "for category in CATEGORIES:\n",
    "    for filename in os.listdir(folder+category):\n",
    "        file_path = os.path.join(folder+category, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7157c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aljadd\n",
      "nossaiba\n",
      "nouhaila\n",
      "langze\n",
      "unknown\n"
     ]
    }
   ],
   "source": [
    "# Prepare images\n",
    "number_of_faces_per_class = 5\n",
    "for category in CATEGORIES:\n",
    "    print(category)\n",
    "\n",
    "    # Randomly take 5 images for training\n",
    "    for c in random.sample(glob.glob(f'{source_face_path}{category}/{category}*'), number_of_faces_per_class):\n",
    "        shutil.copy(c, f'{destination_face_path}/{category}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab35f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed functions\n",
    "def normalize(img):\n",
    "    mean, std = img.mean(), img.std()\n",
    "    return (img - mean) / std\n",
    "\n",
    "def get_face(img, box):\n",
    "    x1, y1, width, height = box\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    return face, (x1, y1), (x2, y2)\n",
    "\n",
    "def get_encode(face_encoder, face, size):\n",
    "    face = normalize(face)\n",
    "    face = cv2.resize(face, size)\n",
    "    encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]\n",
    "    return encode\n",
    "\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        encoding_dict = pickle.load(f)\n",
    "    return encoding_dict\n",
    "\n",
    "def detect(img ,detector,encoder,encoding_dict):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = detector.detect_faces(img_rgb)\n",
    "    for res in results:\n",
    "        if res['confidence'] < confidence_t:\n",
    "            continue\n",
    "        face, pt_1, pt_2 = get_face(img_rgb, res['box'])\n",
    "        encode = get_encode(encoder, face, required_size)\n",
    "        encode = l2_normalizer.transform(encode.reshape(1, -1))[0]\n",
    "        name = 'unknown'\n",
    "\n",
    "        distance = float(\"inf\")\n",
    "        for db_name, db_encode in encoding_dict.items():\n",
    "            dist = cosine(db_encode, encode)\n",
    "            if dist < recognition_t and dist < distance:\n",
    "                name = db_name\n",
    "                distance = dist\n",
    "\n",
    "        if name == 'unknown':\n",
    "            cv2.rectangle(img, pt_1, pt_2, (0, 0, 255), 2)\n",
    "            cv2.putText(img, name, pt_1, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n",
    "        else:\n",
    "            cv2.rectangle(img, pt_1, pt_2, (0, 255, 0), 2)\n",
    "            cv2.putText(img, name + f'__{distance:.2f}', (pt_1[0], pt_1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                        (0, 200, 200), 2)\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f56088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained FaceNet\n",
    "face_data = destination_face_path\n",
    "required_shape = (160,160)\n",
    "face_encoder = InceptionResNetV2()\n",
    "path = \"FaceNet_src/facenet_keras_weights.h5\"\n",
    "face_encoder.load_weights(path)\n",
    "face_detector = mtcnn.MTCNN()\n",
    "encodes = []\n",
    "encoding_dict = dict()\n",
    "l2_normalizer = Normalizer('l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34b3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "for face_names in os.listdir(face_data):\n",
    "    person_dir = os.path.join(face_data,face_names)\n",
    "\n",
    "    for image_name in os.listdir(person_dir):\n",
    "        image_path = os.path.join(person_dir,image_name)\n",
    "\n",
    "        img_BGR = cv2.imread(image_path)\n",
    "        img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        x = face_detector.detect_faces(img_RGB)\n",
    "        x1, y1, width, height = x[0]['box']\n",
    "        x1, y1 = abs(x1) , abs(y1)\n",
    "        x2, y2 = x1+width , y1+height\n",
    "        face = img_RGB[y1:y2 , x1:x2]\n",
    "        \n",
    "        face = normalize(face)\n",
    "        face = cv2.resize(face, required_shape)\n",
    "        face_d = np.expand_dims(face, axis=0)\n",
    "        encode = face_encoder.predict(face_d)[0]\n",
    "        encodes.append(encode)\n",
    "\n",
    "    if encodes:\n",
    "        encode = np.sum(encodes, axis=0 )\n",
    "        encode = l2_normalizer.transform(np.expand_dims(encode, axis=0))[0]\n",
    "        encoding_dict[face_names] = encode\n",
    "        \n",
    "confidence_t=0.99\n",
    "recognition_t=0.5\n",
    "required_size = (160,160)\n",
    "\n",
    "path = 'FaceNet_src/encodings/encodings.pkl'\n",
    "with open(path, 'wb') as file:\n",
    "    pickle.dump(encoding_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f4953",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d82a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_shape = (160,160)\n",
    "face_encoder = InceptionResNetV2()\n",
    "path_m = \"FaceNet_src/facenet_keras_weights.h5\"\n",
    "face_encoder.load_weights(path_m)\n",
    "encodings_path = 'FaceNet_src/encodings/encodings.pkl'\n",
    "face_detector = mtcnn.MTCNN()\n",
    "encoding_dict = load_pickle(encodings_path)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"CAM NOT OPEND\") \n",
    "        break\n",
    "\n",
    "    frame= detect(frame , face_detector , face_encoder , encoding_dict)\n",
    "\n",
    "    cv2.imshow('camera', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
